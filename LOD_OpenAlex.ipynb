{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iUx6BsOuCEJ86A1MSIYxw1SAzqfQ3YIc",
      "authorship_tag": "ABX9TyM+42U+3LCQNPyU8tFBftFi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafabarros95/DS_LOD_and_Knowledge_Graphs_2024_Rafael_Barros_and_Habiba_Naeem/blob/main/LOD_OpenAlex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Knowledge Graph with OpenAlex"
      ],
      "metadata": {
        "id": "X0wg_VVoUypO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra necessary packages"
      ],
      "metadata": {
        "id": "vswp-6Xqcbhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas requests tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yhm9HEJ5cfDN",
        "outputId": "f960c42d-b30b-42dd-993e-6b379940b214"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "3wdYC7j8U8cE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DMi9TsdEUpUg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from urllib.parse import urlencode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constants\n",
        "API_URL = \"https://api.openalex.org/works\"\n",
        "TOTAL_WORKS = 5000\n",
        "BATCH_SIZE = 200  # Maximum allowed by OpenAlex per request\n",
        "HEADERS = {\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "8Zt8-H2zaq4m"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetching Data through API"
      ],
      "metadata": {
        "id": "Rd1nogIKXMKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fetch data from OpenAlex - 5000 Works\n",
        "def fetch_openalex_works(total_works=5000, batch_size=200):\n",
        "    works = []\n",
        "    pages = total_works // batch_size\n",
        "    remainder = total_works % batch_size\n",
        "    total_pages = pages + (1 if remainder else 0)\n",
        "\n",
        "    for page in tqdm(range(total_pages), desc=\"Fetching works\"):\n",
        "        limit = batch_size if page < pages else remainder\n",
        "        params = {\n",
        "            'per-page': limit,\n",
        "            'page': page + 1\n",
        "        }\n",
        "        response = requests.get(API_URL, headers=HEADERS, params=params)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            works.extend(data['results'])\n",
        "        else:\n",
        "            print(f\"Failed to fetch page {page + 1}: Status code {response.status_code}\")\n",
        "            break\n",
        "    return works"
      ],
      "metadata": {
        "id": "oAoc_jCcX4Ty"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Extraction - Relevant Relationships\n"
      ],
      "metadata": {
        "id": "AzqRKSZEYoyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract relationships listed to data{}\n",
        "def extract_relationships(works):\n",
        "    data = {\n",
        "        'work_id': [],\n",
        "        'title': [],\n",
        "        'authored_by': [],\n",
        "        'has_topic': [],\n",
        "        'affiliated_with': [],\n",
        "        'belongs_to_domain': [],\n",
        "        'belongs_to_subfield': [],\n",
        "        'belongs_to_field': [],\n",
        "        'published_in': []\n",
        "    }\n",
        "\n",
        "    for work in works:\n",
        "        data['work_id'].append(work.get('id', None))\n",
        "        data['title'].append(work.get('title', None))\n",
        "\n",
        "        # Authored_by\n",
        "        authors = work.get('authorships', [])\n",
        "        author_names = [author.get('author', {}).get('display_name') for author in authors if author.get('author', {}).get('display_name')]\n",
        "        data['authored_by'].append('; '.join(author_names) if author_names else None)\n",
        "\n",
        "        # has_topic\n",
        "        concepts = work.get('concepts', [])\n",
        "        topics = [concept.get('display_name') for concept in concepts if concept.get('display_name')]\n",
        "        data['has_topic'].append('; '.join(topics) if topics else None)\n",
        "\n",
        "        # affiliated_with\n",
        "        institutions = set()\n",
        "        for author in authors:\n",
        "            insts = author.get('author', {}).get('affiliations', [])\n",
        "            for inst in insts:\n",
        "                inst_name = inst.get('display_name')\n",
        "                if inst_name:\n",
        "                    institutions.add(inst_name)\n",
        "        data['affiliated_with'].append('; '.join(institutions) if institutions else None)\n",
        "\n",
        "        # belongs_to_domain, subfield, field\n",
        "        # OpenAlex classifies concepts into three hierarchical levels: domain, subfield, field\n",
        "        domains = set()\n",
        "        subfields = set()\n",
        "        fields = set()\n",
        "        for concept in concepts:\n",
        "            if 'level' in concept:\n",
        "                if concept['level'] == 0:\n",
        "                    domains.add(concept.get('display_name'))\n",
        "                elif concept['level'] == 1:\n",
        "                    subfields.add(concept.get('display_name'))\n",
        "                elif concept['level'] == 2:\n",
        "                    fields.add(concept.get('display_name'))\n",
        "        data['belongs_to_domain'].append('; '.join(domains) if domains else None)\n",
        "        data['belongs_to_subfield'].append('; '.join(subfields) if subfields else None)\n",
        "        data['belongs_to_field'].append('; '.join(fields) if fields else None)\n",
        "\n",
        "        # published_in\n",
        "        venue = work.get('host_venue', {})\n",
        "        venue_name = venue.get('display_name')\n",
        "        data['published_in'].append(venue_name if venue_name else None)\n",
        "\n",
        "    return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "VSmCH6FeYuY_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data into Dataframe"
      ],
      "metadata": {
        "id": "OFOs1ZPJJMAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch works from OpenAlex\n",
        "works = fetch_openalex_works(TOTAL_WORKS, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "rojxLtbaJTLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d748e7e0-c888-4683-f49b-786b20fa0742"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching works: 100%|██████████| 25/25 [00:23<00:00,  1.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking for Inconsistency followed by Cleaning"
      ],
      "metadata": {
        "id": "IU0IbmmvJndi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not works:\n",
        "    print(\"No works were fetched. Please check the API parameters and try again.\")\n",
        "else:\n",
        "    # Extract relationships\n",
        "    df = extract_relationships(works)\n",
        "\n",
        "    # Cleaning the data: Replace empty strings with NaN and drop duplicates.\n",
        "    # By default, OpenAlex Structure in Json data format is quite clean actually\n",
        "    df.replace('', pd.NA, inplace=True)\n",
        "    df.drop_duplicates(subset=['work_id'], inplace=True)\n",
        "\n",
        "    # Display first few rows\n",
        "    print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWyE3eisJpkT",
        "outputId": "f6521373-6d95-4f95-9e44-483a30e3daca",
        "collapsed": true
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            work_id  \\\n",
            "0  https://openalex.org/W1775749144   \n",
            "1  https://openalex.org/W2582743722   \n",
            "2  https://openalex.org/W2100837269   \n",
            "3  https://openalex.org/W2128635872   \n",
            "4  https://openalex.org/W4293247451   \n",
            "\n",
            "                                               title  \\\n",
            "0  PROTEIN MEASUREMENT WITH THE FOLIN PHENOL REAGENT   \n",
            "1  R: A language and environment for statistical ...   \n",
            "2  Cleavage of Structural Proteins during the Ass...   \n",
            "3  A Rapid and Sensitive Method for the Quantitat...   \n",
            "4  A rapid and sensitive method for the quantitat...   \n",
            "\n",
            "                                         authored_by  \\\n",
            "0  OliverH. Lowry; NiraJ. Rosebrough; A. Farr; Ro...   \n",
            "1                                        R Core Team   \n",
            "2                                  Ulrich K. Laemmli   \n",
            "3                                   Mark A. Bradford   \n",
            "4                                 Marion M. Bradford   \n",
            "\n",
            "                                           has_topic affiliated_with  \\\n",
            "0  Reagent; Chemistry; Phenol; Chromatography; Or...            None   \n",
            "1             Computer science; Programming language            None   \n",
            "2  Bacteriophage; Cleavage (geology); Gel electro...            None   \n",
            "3  Chemistry; Coomassie Brilliant Blue; Chromatog...            None   \n",
            "4  Chemistry; Coomassie Brilliant Blue; Chromatog...            None   \n",
            "\n",
            "              belongs_to_domain  \\\n",
            "0                     Chemistry   \n",
            "1              Computer science   \n",
            "2            Biology; Chemistry   \n",
            "3  Physics; Chemistry; Medicine   \n",
            "4  Physics; Chemistry; Medicine   \n",
            "\n",
            "                                 belongs_to_subfield  \\\n",
            "0                  Organic chemistry; Chromatography   \n",
            "1                               Programming language   \n",
            "2  Computational biology; Biochemistry; Paleontology   \n",
            "3  Acoustics; Organic chemistry; Chromatography; ...   \n",
            "4  Chromatography; Pathology; Acoustics; Biochemi...   \n",
            "\n",
            "                                    belongs_to_field published_in  \n",
            "0                                    Phenol; Reagent         None  \n",
            "1                                               None         None  \n",
            "2  Gene; Fracture (geology); Gel electrophoresis;...         None  \n",
            "3  Sodium; Absorption (acoustics); Staining; Sodi...         None  \n",
            "4  In vitro; Sodium; Absorption (acoustics); Stai...         None  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing into CSV File"
      ],
      "metadata": {
        "id": "bE2z7yNoK6l0"
      }
    },
    {
      "source": [
        "# Save to CSV\n",
        "csv_filename = 'openalex_works_relationships.csv'\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "# Download link\n",
        "from google.colab import files\n",
        "files.download(csv_filename)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qlBSnrzHFJeq",
        "outputId": "8f6be3e7-eb39-4eb7-9d8e-7c664cd05bf8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2caf6705-051e-4911-a5f0-cdfd34a0d185\", \"openalex_works_relationships.csv\", 2837119)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}